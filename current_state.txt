composition, interactions, déroulement, résolution de problèmes de toute nature et tout élément pertinent sur le travail d’équipe. 
Pour l’option 2, la conception doit être présentée clairement Pour la partie le codage remettre les codes sources, compilés avec une documentation d’utilisation. Rajouter au  fichier Word (conception)   les résultats des tests. Pour chaque option une liste de références est nécessaire avec des citations au niveau du texte et l’intégration à la liste à présenter a la fin du document. Le rapport doit être bien structuré avec des titres significatifs et des illustrations incluant des captures écran. Le rapport ne doit pas dépasser 15 pages pour les deux options et au besoin utiliser une annexe pour le code ou les illustrations

Le projet utilise CARLA comme environnement pour l'agent.

Initialement on pensait que l'interaction avec le serveur serait simple.

Le premier problème rencontré avait avoir avec l'utilisation de CARLA parce que customiser les cartes sur lesquelles faire pratiquer notre agent n'était pas simple.

Notre solution est un mélange de cartes généré par l'entremise du standard openDRIVE et l'utiliation des cartes par défaut pour la validation de l'apprentissage.

L'implantation d'un agent apprenant dans CARLA est complexe à cause de la difficulté qui existe à rendre les données du simulateur compatible avec un agent créé avec notre module de machine learning de choix (PyTorch).

Notre solution tentative implique utiliser le module gymnasium comme wrapper pour les données liés au simulateur et en suite les passer au code d'apprentissage.

Je comptais utiliser le lidar pour obtenir la distance vers les obstacles mais le fait qu'il doit tourner pour avoir une bonne détection des alentours veux dire qu'il est plus difficile pour l'agent de faire du sens de ses données si elle sont réduites en une distance relative.

Les problemes rencontrés avec le radar ont principalement a voir avec bien définir ou il pointe ce qui à demandé l'ajout d'un outil pour visionné ce qui voit le véhicule.

Tester les capteurs de l'agent c'est fait à l'aide de code pour pourvoir observer ou le radar pointe et les données qu'il retourne.

Ces données sont aussi présenté dans le dashboard de l'enviromment qui l'affiche sous forme de carte top down avec les lignes généré par le radar.

Compte-tenu que notre but est seulemen de faire l'évitement d'autre capteurs ne sont pas nécessaires

Je suis retourné au capteur liDAR parce qu'il offre une meilleur précision dans ces observations
Ses données sont transformé en un liste de points boolean qui représente true si il n'y a rien et false si il y a un obstacle


Comme il est très difficile pour moi de voir comment discretisé l'état de ma simulation, j'ai décidé d'utiliser une version de deep learning pour le moment.
Deep q learning fait l'affaire parce que discretisé les actions possibles est très simple.

04-01 Mon problème actuel est de faire fonctionné ensemble toute les couches de mon réseau neuronal.
Solutions tentatives:
Changer les couches précédents la couche problématique (ceci requiert modifier les données entrants de mon réseaux)
Faire plus de modification intermédiaires sur les données
Le but du réseau est de finir avec une valeur entière entre 0 et 4

le fichier test contient l'implantation de deep q learning la plus à jour.

Il y a beaucoup de nombres a ajusté et beaucoup de modifications à faire dans le code de l'agent

Known issues:
l'optimisateur de model cause des erreurs à cause de changement de taille
hypothesis 1 : Error related to reset causing speed too reach out of bounds speeds

BATCH_SIZE must be a multiple of 508 because that is th return size of the neural net

Ajout de l'implantation de PPO implanter avec F1tenth

Donner plus de temps au système pour découvrir quoi faire par épisode serait bénéfique